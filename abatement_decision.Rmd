---
title: "R Notebook"
output:
  html_document: default
  html_notebook: default
---

 

```{r}

library(AppliedPredictiveModeling)
library(caret)
library(feather)
library(forcats)
library(gbm)
library(modelr)
library(stringr)
library(tidyverse)

raw <- read_feather("./data/decisions.feather")

decisions <- raw %>% 
  select(-c(council_district, fire_district)) %>% 
  filter(tier != "2") %>% 
  rename(outcome = tier)

# Preprocessing -----------------------------------------------------------

num_col_indices <- map_lgl(decisions, is.numeric)
fact_col_inds <- 8:ncol(decisions)

fact_cols <- map(decisions[,fact_col_inds], factor) %>% 
  as_tibble()

fact_cols$mva_value <- fct_collapse(fact_cols$mva_value,
                                    high = c('A', 'B', 'C'),
                                    medium = c('D', 'E', 'F'),
                                    low = c('G', 'H'))

fact_cols$occupancy_use <- fct_collapse(fact_cols$occupancy_use,
                                    residential = c('Residential'),
                                    commercial = c('Commercial', 'Mixed Use'),
                                    vacant_lot = c('Vacant Lot'))

na_percs <- map_dbl(fact_cols, ~sum(is.na(.)/length(.)))
na_percs_logical <- na_percs < 0.05

num_levels <- map_int(fact_cols, ~length(levels(.)))
num_levels_logical <- num_levels <= 5

perc_greatest <- map(fact_cols, ~max(table(.)/length(.)))
perc_greatest_logical <- perc_greatest < 0.95

fact_cols <- fact_cols[, na_percs_logical & num_levels_logical & perc_greatest_logical]
complete_indices <- complete.cases(fact_cols)

# diagnose problems with categorical variables

map(fact_cols, ~table(.)/length(.))

sum(complete_indices)

# rejoin numeric variables

num_cols <- decisions[complete_indices, num_col_indices]
fact_cols <- fact_cols[complete_indices,]

with_cats <- bind_cols(decisions['outcome'][complete_indices,], num_cols, fact_cols)

# process numeric variables

mod_dat <- with_cats

# mod_dat <- decisions %>% 
#   select(outcome, violations:taxes_to_value)

mod_dat$outcome <- fct_recode(mod_dat$outcome, high = "1", low = "3")

```
```{r scatterplots}

transparentTheme(trans = .4)
featurePlot(x = mod_dat[, 2:7], 
            y = mod_dat$outcome,
            plot = "pairs",
            ## Add a key at the top
            auto.key = list(columns = 2))

```

```{r box_plots}

fpb <- featurePlot(x = mod_dat[, 2:7], 
            y = mod_dat$outcome, 
            plot = "box", 
            ## Pass in options to bwplot() 
            scales = list(y = list(relation="free"),
                          x = list(rot = 90)),  
            layout = c(6, 1), 
            auto.key = list(columns = 2))

trellis.device(device = "png", filename = "boxplots.png")
print(fpb)
dev.off()

fpb

```

```{r boxplots_by_category}

mod_dat %>% 
  ggplot(aes(x = occupancy_use, fill = outcome)) +
  geom_bar(position = 'fill')

mod_dat %>% 
  ggplot(aes(x = mva_value, fill = outcome)) +
  geom_bar(position = 'fill')

mod_dat %>% 
  ggplot(aes(x = in_national_historic_district, fill = outcome)) +
  geom_bar(position = 'fill')

mod_dat %>% 
  ggplot(aes(x = in_neighborhood_conservation_district, fill = outcome)) +
  geom_bar(position = 'fill')

```

```{r feature_selection, eval=FALSE}

mod_dat <- mod_dat %>% 
  select(-mva_value, -value)

```


```{r}

set.seed(1)

in_train <- createDataPartition(mod_dat$outcome, list = FALSE, p = 0.75)

training <- mod_dat[in_train,]
testing <- mod_dat[-in_train,]

# Impute missing numeric values
pp <- preProcess(training, method = c("scale",
                                      "center",
                                      "bagImpute"))

training <- predict(pp, training)
testing <- predict(pp, testing)

train_control <- trainControl(method = "repeatedcv",
                              summaryFunction = twoClassSummary,
                              classProbs = TRUE,
                              number = 4,
                              repeats = 4)

```

```{r glmnet}

# Train model using cross-validation
glm_fit <- train(form = outcome ~ .,
             data = training,
             method = 'glmnet',
             metric = 'ROC',
             trControl = train_control)

# Results -----------------------------------------------------------------

print(glm_fit$results)
pred <- predict(glm_fit, newdata = testing)
print(confusionMatrix(data = pred, testing$outcome, positive = "high", mode = 'everything'))

varImp(glm_fit) %>% plot()
glm_imp <- varImp(glm_fit)

```

```{r rf}

# Train model using cross-validation
fit <- train(form = outcome ~ .,
             data = training,
             method = 'rf',
             metric = 'ROC',
             trControl = train_control)

# Results -----------------------------------------------------------------

print(fit$results)
pred <- predict(fit, newdata = testing)
print(confusionMatrix(data = pred, testing$outcome, positive = "high"))

varImp(fit) %>% plot()
rf_imp <- varImp(fit)

```

```{r gbm}

# Train model using cross-validation
fit <- train(form = outcome ~ .,
             data = training,
             method = 'gbm',
             verbose = FALSE,
             metric = 'ROC',
             trControl = train_control)

# Results -----------------------------------------------------------------

print(fit$results)
pred <- predict(fit, newdata = testing)
print(confusionMatrix(data = pred, testing$outcome, positive = "high"))

varImp(fit)
varImp(fit) %>% plot()

```

```{r}

glm_imp %>% plot()
rf_imp %>% plot()

```

